import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
import platform
import xgboost as xgb
import csv
import os
from datetime import datetime

# 1. åˆå§‹è¨­å®š
# ---------------------------------------------------------
warnings.filterwarnings('ignore')

# è¨­å®šä¸­æ–‡å­—å‹ (æ ¹æ“šä½œæ¥­ç³»çµ±è‡ªå‹•é¸æ“‡ï¼Œé¿å…äº‚ç¢¼)
system_name = platform.system()
if system_name == "Windows":
    plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei']
elif system_name == "Darwin":  # Mac
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']
else:  # Linux / Colab
    plt.rcParams['font.sans-serif'] = ['DejaVu Sans'] 

plt.rcParams['axes.unicode_minus'] = False


# 2. è³‡æ–™è™•ç†å‡½æ•¸
# ---------------------------------------------------------
def load_and_preprocess_data(filepath):
    """
    è®€å–ä¸¦é è™•ç†è³‡æ–™
    """
    df = pd.read_csv(filepath)
    
    # ç¢ºä¿æ™‚é–“æ¬„ä½æ˜¯ datetime æ ¼å¼
    df['rent_time'] = pd.to_datetime(df['rent_time'])

    # X = df.drop(['rent_count', 'rent_time'], axis=1)
    # X = pd.get_dummies(X, columns=['rent_station', 'sarea'], drop_first=True)
    X=df[['hour', 'weekday', 'month', 'rent_station']]
    # X = pd.get_dummies(X, columns=['rent_station', 'sarea'], drop_first=True)
    X = pd.get_dummies(X, columns=['rent_station'], drop_first=True)
    y = df['rent_count']
    
    print(f"âœ… è³‡æ–™è™•ç†å®Œæˆã€‚æ¨£æœ¬æ•¸: {X.shape[0]}, ç‰¹å¾µæ•¸: {X.shape[1]}")
    return X, y, df['rent_time'], X.columns


# 3. è¨“ç·´èˆ‡è©•ä¼°å‡½æ•¸
# ---------------------------------------------------------
def save_results(experiment_id, model_name, mae, rmse, r2, feature_names, filename="experiment_results.csv"):
    """
    å°‡å¯¦é©—çµæœå„²å­˜è‡³ CSV æª”æ¡ˆ
    """
    file_exists = os.path.isfile(filename)
    with open(filename, mode='a', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        # ä¿®æ”¹ï¼šæ–°å¢ Experiment_ID æ¬„ä½
        if not file_exists:
            writer.writerow(['Experiment_ID', 'Timestamp', 'Model', 'MAE', 'RMSE', 'R2', 'Features'])
        
        features_str = "; ".join(map(str, feature_names))
        # ä¿®æ”¹ï¼šå¯«å…¥ experiment_id
        writer.writerow([experiment_id, datetime.now().strftime("%Y-%m-%d %H:%M:%S"), model_name, f"{mae:.4f}", f"{rmse:.4f}", f"{r2:.4f}", features_str])
    print(f"âœ… çµæœå·²å„²å­˜è‡³ {filename} (ID: {experiment_id})")

def train_and_evaluate(model, X_train, y_train, X_test, y_test, model_name, experiment_id):
    """
    è¨“ç·´æ¨¡å‹ä¸¦è¨ˆç®—è©•ä¼°æŒ‡æ¨™
    """
    print(f"\nğŸ”„ æ­£åœ¨è¨“ç·´ {model_name} ...")
    model.fit(X_train, y_train)
    
    # é æ¸¬
    y_pred = model.predict(X_test)
    
    # è™•ç†è² å€¼ (å€Ÿè»Šæ•¸ä¸ç‚ºè² )
    y_pred = np.maximum(y_pred, 0)
    
    # è¨ˆç®—æŒ‡æ¨™
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    
    print(f"ğŸ“Š {model_name} è©•ä¼°çµæœ:")
    print(f"   MAE  : {mae:.4f}")
    print(f"   RMSE : {rmse:.4f}")
    print(f"   R2   : {r2:.4f}")
    
    feature_names = X_train.columns.tolist() if hasattr(X_train, 'columns') else []
    # ä¿®æ”¹ï¼šå‚³å…¥ experiment_id
    save_results(experiment_id, model_name, mae, rmse, r2, feature_names)

    return y_pred, model


# 4. ç¹ªåœ–å‡½æ•¸
# ---------------------------------------------------------
def get_feature_str(feature_names):
    """
    æ ¹æ“šç‰¹å¾µåç¨±åˆ—è¡¨ç”¢ç”Ÿæª”åå¾Œç¶´
    """
    # ç§»é™¤å¯èƒ½å°è‡´æª”åéæ³•çš„å­—å…ƒ
    clean_names = [str(f).replace(':', '').replace('/', '') for f in feature_names]
    
    full_str = "_".join(clean_names)
    # å¦‚æœæª”åå¤ªé•· (ä¾‹å¦‚ç”¨äº† One-Hot Encoding)ï¼Œå‰‡ç°¡åŒ–é¡¯ç¤ºç‰¹å¾µæ•¸é‡
    if len(full_str) > 50:
        return f"{len(feature_names)}_Features"
    return full_str

def save_plot(filename, folder):
    """
    å„²å­˜åœ–è¡¨åˆ°æŒ‡å®šè³‡æ–™å¤¾
    """
    if not os.path.exists(folder):
        os.makedirs(folder)
    
    path = os.path.join(folder, filename)
    plt.savefig(path)
    print(f"ğŸ’¾ åœ–è¡¨å·²å„²å­˜: {path}")

def plot_predictions(y_test, predictions_dict, time_index, feature_str, folder):
    """
    ç¹ªè£½æ™‚é–“åºåˆ—é æ¸¬å°æ¯”åœ– (æœ€å¾Œ 100 ç­†)
    """
    plt.figure(figsize=(14, 6))
    
    subset_n = 200
    if len(y_test) < subset_n:
        subset_n = len(y_test)
        
    subset_y_test = y_test[-subset_n:].values
    
    plt.plot(subset_y_test, label='å¯¦éš›å€¼ (Actual)', color='black', linewidth=2, linestyle='--')
    
    colors = {'Linear Regression': '#1f77b4', 'Random Forest': '#2ca02c', 'XGBoost': '#d62728'}
    
    for name, y_pred in predictions_dict.items():
        subset_y_pred = y_pred[-subset_n:]
        color = colors.get(name, 'orange')
        plt.plot(subset_y_pred, label=f'{name} é æ¸¬', color=color, alpha=0.8)

    plt.title(f'æ¨¡å‹é æ¸¬çµæœå°æ¯” (æœ€å¾Œ {subset_n} ç­†è³‡æ–™)')
    plt.xlabel('æ™‚é–“é †åº')
    plt.ylabel('å€Ÿè»Šæ•¸é‡')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    # å„²å­˜åœ–è¡¨
    save_plot(f"Predictions_{feature_str}.png", folder)
    plt.show()

def plot_feature_importance(model, feature_names, model_name, feature_str, folder):
    """
    ç¹ªè£½ç‰¹å¾µé‡è¦æ€§ (åƒ…é©ç”¨æ–¼æ¨¹æ¨¡å‹)
    """
    if not hasattr(model, 'feature_importances_'):
        return

    importances = model.feature_importances_
    indices = np.argsort(importances)[::-1]
    
    # åªé¡¯ç¤ºå‰ 15 å€‹é‡è¦ç‰¹å¾µï¼Œè‹¥ç‰¹å¾µä¸è¶³ 15 å€‹å‰‡é¡¯ç¤ºå…¨éƒ¨
    top_n = min(15, len(importances))
    top_indices = indices[:top_n]
    
    plt.figure(figsize=(10, 6))
    plt.title(f'{model_name} - å‰ {top_n} é‡è¦ç‰¹å¾µ')
    plt.bar(range(top_n), importances[top_indices], align='center', color='skyblue')
    plt.xticks(range(top_n), [feature_names[i] for i in top_indices], rotation=45, ha='right')
    plt.xlabel('ç‰¹å¾µåç¨±')
    plt.ylabel('é‡è¦æ€§åˆ†æ•¸')
    plt.tight_layout()
    
    # å„²å­˜åœ–è¡¨
    save_plot(f"FeatureImportance_{model_name}_{feature_str}.png", folder)
    plt.show()

def plot_actual_vs_predicted(y_test, y_pred, model_name, feature_str, folder):
    """
    ç¹ªè£½ çœŸå¯¦å€¼ vs é æ¸¬å€¼ çš„æ•£ä½ˆåœ–
    """
    plt.figure(figsize=(8, 8))
    plt.scatter(y_test, y_pred, alpha=0.3, color='blue')
    
    # ç•«å‡ºå®Œç¾çš„ 45 åº¦å°è§’ç·š
    p1 = max(max(y_pred), max(y_test))
    p2 = min(min(y_pred), min(y_test))
    plt.plot([p1, p2], [p1, p2], 'r--', label='å®Œç¾é æ¸¬ç·š')
    
    plt.title(f'{model_name}: çœŸå¯¦å€¼ vs é æ¸¬å€¼')
    plt.xlabel('çœŸå¯¦å€Ÿè»Šæ•¸ (Actual)')
    plt.ylabel('é æ¸¬å€Ÿè»Šæ•¸ (Predicted)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    # å„²å­˜åœ–è¡¨
    save_plot(f"Scatter_{model_name}_{feature_str}.png", folder)
    plt.show()

def plot_hourly_comparison(y_test, y_pred, time_index, model_name, feature_str, folder):
    """
    ç¹ªè£½ å¹³å‡å°æ™‚è¶¨å‹¢åœ– (æª¢æŸ¥æ˜¯å¦æŠ“åˆ°æ—©æ™šé«˜å³°)
    """
    # å»ºç«‹ä¸€å€‹è‡¨æ™‚ DataFrame ä¾†æ–¹ä¾¿è¨ˆç®—å¹³å‡
    df_temp = pd.DataFrame({
        'Actual': y_test.values,
        'Predicted': y_pred,
        'Hour': time_index.dt.hour
    })
    
    # ä¾å°æ™‚åˆ†çµ„è¨ˆç®—å¹³å‡å€¼
    hourly_avg = df_temp.groupby('Hour').mean()
    
    plt.figure(figsize=(10, 6))
    plt.plot(hourly_avg.index, hourly_avg['Actual'], 'o-', label='çœŸå¯¦å¹³å‡', color='black', linewidth=2)
    plt.plot(hourly_avg.index, hourly_avg['Predicted'], 'o--', label='é æ¸¬å¹³å‡', color='red', linewidth=2)
    
    plt.title(f'{model_name}: å¹³å‡æ¯å°æ™‚å€Ÿè»Šé‡è¶¨å‹¢')
    plt.xlabel('å°æ™‚ (0-23)')
    plt.ylabel('å¹³å‡å€Ÿè»Šæ•¸')
    plt.xticks(range(0, 24))
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    # å„²å­˜åœ–è¡¨
    save_plot(f"HourlyTrend_{model_name}_{feature_str}.png", folder)
    plt.show()

def plot_residuals_histogram(y_test, y_pred, model_name, feature_str, folder):
    """
    ç¹ªè£½ æ®˜å·® (èª¤å·®) åˆ†ä½ˆç›´æ–¹åœ–
    """
    residuals = y_test - y_pred
    plt.figure(figsize=(10, 6))
    sns.histplot(residuals, kde=True, color='purple', bins=30)
    plt.axvline(x=0, color='red', linestyle='--', linewidth=2)
    plt.title(f'{model_name}: æ®˜å·®åˆ†ä½ˆ (Residuals)')
    plt.xlabel('èª¤å·®å€¼ (çœŸå¯¦ - é æ¸¬)')
    plt.ylabel('é »ç‡')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    # å„²å­˜åœ–è¡¨
    save_plot(f"Residuals_{model_name}_{feature_str}.png", folder)
    plt.show()


# 5. ä¸»ç¨‹å¼
# ---------------------------------------------------------
if __name__ == "__main__":
    # æª”æ¡ˆåç¨±è¨­å®š
    FILENAME = 'FINAL_MODEL_DATA_CLEAN.csv'
    
    # è¼‰å…¥è³‡æ–™
    X, y, time_col, feature_names = load_and_preprocess_data(FILENAME)
    
    # ç”¢ç”Ÿç”¨æ–¼æª”åçš„ç‰¹å¾µå­—ä¸²
    feature_str = get_feature_str(feature_names)
    
    # ä¿®æ”¹ï¼šå»ºç«‹å”¯ä¸€çš„å¯¦é©—ç·¨è™Ÿ (ID)
    experiment_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # å»ºç«‹æœ¬æ¬¡å¯¦é©—çš„å°ˆå±¬è³‡æ–™å¤¾ (ID + ç‰¹å¾µç°¡ç¨±)
    experiment_folder = os.path.join("results", f"{experiment_id}_{feature_str}")
    if not os.path.exists(experiment_folder):
        os.makedirs(experiment_folder)
        
    print(f"ğŸ†” æœ¬æ¬¡å¯¦é©—ç·¨è™Ÿ: {experiment_id}")
    print(f"ğŸ“ æœ¬æ¬¡å¯¦é©—ç‰¹å¾µæ¨™ç±¤: {feature_str}")
    print(f"ğŸ“‚ å¯¦é©—çµæœå°‡å„²å­˜æ–¼: {experiment_folder}")
    
    if X is not None:
        # ä¿®æ”¹ï¼šæŒ‡å®š 3 æœˆä»½è³‡æ–™ä½œç‚ºæ¸¬è©¦é›† (Test Set)ï¼Œå…¶é¤˜ç‚ºè¨“ç·´é›†
        print("â„¹ï¸ æ­£åœ¨æ ¹æ“šæœˆä»½åˆ‡åˆ†è³‡æ–™ï¼š3æœˆç‚ºæ¸¬è©¦é›†...")
        
        # å»ºç«‹ 3 æœˆä»½çš„é®ç½© (Mask)
        test_mask = time_col.dt.month == 3
        train_mask = ~test_mask
        
        X_train, X_test = X[train_mask], X[test_mask]
        y_train, y_test = y[train_mask], y[test_mask]
        test_time = time_col[test_mask]
        
        print(f"è¨“ç·´é›† (é3æœˆ): {len(X_train)} ç­†, æ¸¬è©¦é›† (3æœˆ): {len(X_test)} ç­†")
        
        if len(X_test) == 0:
            print("âŒ è­¦å‘Šï¼šæ‰¾ä¸åˆ° 3 æœˆä»½çš„è³‡æ–™ï¼è«‹æª¢æŸ¥è³‡æ–™æ—¥æœŸç¯„åœã€‚")
        
        predictions = {}
        models = {}

        # --- æ¨¡å‹ 1: Linear Regression (ç·šæ€§å›æ­¸) ---
        lr = LinearRegression()
        # ä¿®æ”¹ï¼šå‚³å…¥ experiment_id
        pred_lr, model_lr = train_and_evaluate(lr, X_train, y_train, X_test, y_test, "Linear Regression", experiment_id)
        predictions['Linear Regression'] = pred_lr
        models['Linear Regression'] = model_lr

        # --- æ¨¡å‹ 2: Random Forest (éš¨æ©Ÿæ£®æ—) ---
        # n_estimators: æ¨¹çš„æ•¸é‡, max_depth: æ¨¹çš„æœ€å¤§æ·±åº¦ (é¿å…éæ“¬åˆ)
        rf = RandomForestRegressor(n_estimators=100, max_depth=7, random_state=42, n_jobs=-1)
        # ä¿®æ”¹ï¼šå‚³å…¥ experiment_id
        pred_rf, model_rf = train_and_evaluate(rf, X_train, y_train, X_test, y_test, "Random Forest", experiment_id)
        predictions['Random Forest'] = pred_rf
        models['Random Forest'] = model_rf

        # --- æ¨¡å‹ 3: XGBoost ---
        xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=150, learning_rate=0.1, max_depth=5, random_state=42)
        # ä¿®æ”¹ï¼šå‚³å…¥ experiment_id
        pred_xgb, model_xgb = train_and_evaluate(xgb_model, X_train, y_train, X_test, y_test, "XGBoost", experiment_id)
        predictions['XGBoost'] = pred_xgb
        models['XGBoost'] = model_xgb

        # --- ç¹ªåœ–çµæœ ---
        print("\nğŸ“ˆ æ­£åœ¨ç¹ªè£½é æ¸¬å°æ¯”åœ–...")
        plot_predictions(y_test, predictions, test_time, feature_str, experiment_folder)
        
        # --- ç¹ªè£½éš¨æ©Ÿæ£®æ—çš„ç‰¹å¾µé‡è¦æ€§ ---
        print("ğŸ“Š æ­£åœ¨ç¹ªè£½ç‰¹å¾µé‡è¦æ€§åœ–è¡¨...")
        plot_feature_importance(models['Random Forest'], feature_names, "Random Forest", feature_str, experiment_folder)
        
        plot_feature_importance(models['XGBoost'], feature_names, "XGBoost", feature_str, experiment_folder)
        
        # --- ç¹ªè£½çœŸå¯¦å€¼ vs é æ¸¬å€¼çš„æ•£ä½ˆåœ– ---
        for name, y_pred in predictions.items():
            plot_actual_vs_predicted(y_test, y_pred, name, feature_str, experiment_folder)
        
        # --- ç¹ªè£½æ¯å°æ™‚çš„çœŸå¯¦å€¼èˆ‡é æ¸¬å€¼è¶¨å‹¢ ---
        for name, y_pred in predictions.items():
            plot_hourly_comparison(y_test, y_pred, test_time, name, feature_str, experiment_folder)
        
        # --- ç¹ªè£½æ®˜å·®åˆ†ä½ˆç›´æ–¹åœ– ---
        for name, y_pred in predictions.items():
            plot_residuals_histogram(y_test, y_pred, name, feature_str, experiment_folder)
             
        print("\nâœ… æ‰€æœ‰ç¨‹å¼åŸ·è¡Œå®Œç•¢ã€‚")